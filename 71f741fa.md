# Systolic Architectures

## References
- [Why Systolic Architectures? -- H. T. Kung](http://www.eecs.harvard.edu/~htk/publication/1982-kung-why-systolic-architecture.pdf)
  - Introduction
    - General methodology for mapping high-level computations into hardware structures
    - Data flows from memory in a rhythmic fashion, passing through many
      processing elements before returning to memory.
    - Can be two dimensional (rectangular, triangular, hexagonal) to make use
      of higher degrees of parallelism
    - Data flow may be at multiple speeds in multiple directions -- both inputs
      and (partial) results flow (in classical pipelined systems, only results
      flow)
    - Regularity and reconfigurability arise from modularity
  - Key architectural issues in designing special-purpose systems
    - Simple and regular design
      - Special-purpose systems must be cost effective (to justify their limited
        applicability)
      - Costs = nonrecurring (design) and recurring (parts).  Parts are cheap for
        both special purpose and general purpose systems, so its the design cost
        that must be small to make a special purpose system attractive
      - Design cost can be avoided by using an appropriate architecture:
        decompose into a few types of simple building blocks which are used
        repetitively with simple interfaces. 
      - Simple, regular designs are likely to be modular (can be adjusted for
        various performance/cost goals, i.e. cost can be made proportional to
        performance required)
    - Concurrency and communication
      - Diminishing growth rate for component speed, need to make use of
        concurrent processing elements to continue to improve speed.
      - An increased number of processing elements working simultaneously
        requires significant amounts of coordination and communication.
      - Goal: algorithms that support high concurrency while employing simple,
        regular communication and control.
    - Balancing computation with I/O
      - Goal: balance computation rate with available I/O bandwidth
      - Related: a modular structure can be adjusted to match a
        variety of I/O bandwidths
      - Ideally perform multiple computations per I/O access which requires
        internal storage.
      - Need to arrange computation with an appropriate memory structure to
        balance with I/O time
      - I/O problem is severe when a large computation is performed on a small
        system (need to transfer results to and from the host)
      - Possible to compute I/O-imposed performance limits for computations
      - In practice, problems are "larger" than special-purpose devices, need to
        decompose computation in a way that minimizes I/O
      - Can determine how the size of a system and its memory is related to the
        I/O requirement, and how I/O bandwidth limits the achievable speedup
        ratio
  - Systolic architectures: the basic principle
    - Set of interconnected cells, each capable of performing a simple operation
    - Simple and regular communication and control structures using array or
      tree interconnects
    - Pipelined information flow, communication only occurs at the boundary
      cells
    - Focused on compute bound computations where multiple operations are
      performed on each data item in a repetitive manner
    - Other advantages: modular expansibility, simple and regular data and
      control flows, use of simple and uniform cells, elimination of global
      broadcasting, and fan-in and fast response time.
  -  

